"""
Knowledge Graph Document Analyzer - Main Streamlit App
Direct Pipeline Architecture - Personal Project
"""
import streamlit as st
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Optional
import pytz
import traceback

# Add src to path - consistent with run_app.py pattern
current_file = Path(__file__)
project_root = current_file.parent.parent.parent  # Go up from src/ui/ to project root
src_path = project_root / "src"

sys.path.insert(0, str(project_root))
sys.path.insert(0, str(src_path))

# Debug info (will show in streamlit logs)
print(f"ğŸ Streamlit app starting...")
print(f"ğŸ“‚ Current file: {current_file}")
print(f"ğŸ“‚ Project root: {project_root}")
print(f"ğŸ“‚ Src path: {src_path}")
print(f"ğŸ” Working directory: {os.getcwd()}")

try:
    # Import configurations
    from config.app_config import app_config
    from config.ai_config import ai_config
    
    # Import core modules
    from src.core.knowledge_graph.neo4j_manager import neo4j_manager
    from src.core.knowledge_graph.kg_operations import kg_operations
    from src.core.pipeline.document_processor import DocumentProcessor
    from src.core.profile_generation.profile_generator import ProfileGenerator
    from src.core.qa_generation.question_evaluator import QuestionEvaluator
    
    print("âœ… All imports successful")
    
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    st.error(f"âŒ Import Error: {e}")
    st.error(f"Working directory: {os.getcwd()}")
    st.error(f"Project root: {project_root}")
    st.error(f"Files in project root: {list(project_root.glob('*')) if project_root.exists() else 'Project root not found'}")
    st.stop()

# Page config
st.set_page_config(
    page_title=app_config.name,
    page_icon="ğŸ•¸ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #FF6B6B;
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .status-success {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    .status-warning {
        background-color: #fff3cd;
        border: 1px solid #ffeeba;
        color: #856404;
    }
    .status-error {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
    }
</style>
""", unsafe_allow_html=True)

def initialize_system():
    """Initialize system components"""
    try:
        # Connect to Neo4j
        if not neo4j_manager.connect():
            st.error("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i Neo4j!")
            return False
        
        # Initialize DocumentProcessor for Direct Pipeline
        if ai_config.api_key:
            processor = DocumentProcessor()
            st.session_state['document_processor'] = processor
            
            # Initialize ProfileGenerator
            profile_generator = ProfileGenerator()
            st.session_state['profile_generator'] = profile_generator
            
            # Initialize QuestionEvaluator
            question_evaluator = QuestionEvaluator()
            st.session_state['question_evaluator'] = question_evaluator
        
        # Initialize processing history
        if 'processing_history' not in st.session_state:
            st.session_state['processing_history'] = []
        
        return True
    except Exception as e:
        st.error(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
        return False

def show_system_status():
    """Display system status"""
    st.header("ğŸ“Š Tráº¡ng thÃ¡i há»‡ thá»‘ng")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ—„ï¸ Neo4j Database")
        try:
            health = neo4j_manager.health_check()
            if health["status"] == "connected":
                st.markdown('<div class="status-box status-success">âœ… Káº¿t ná»‘i thÃ nh cÃ´ng</div>', unsafe_allow_html=True)
                if "stats" in health:
                    stats = health["stats"]
                    st.metric("Entities", stats.get("nodes", 0))
                    st.metric("Relationships", stats.get("relationships", 0))
            else:
                st.markdown('<div class="status-box status-error">âŒ Káº¿t ná»‘i tháº¥t báº¡i</div>', unsafe_allow_html=True)
                st.write(health.get("message", "Unknown error"))
        except Exception as e:
            st.markdown('<div class="status-box status-error">âŒ Lá»—i káº¿t ná»‘i</div>', unsafe_allow_html=True)
            st.write(str(e))
    
    with col2:
        st.subheader("ğŸ§  Direct Pipeline Engine")
        try:
            # Check DocumentProcessor status
            has_api_key = bool(ai_config.api_key)
            has_processor = 'document_processor' in st.session_state
            
            if has_processor and has_api_key:
                st.markdown('<div class="status-box status-success">âœ… Direct Pipeline Ready</div>', unsafe_allow_html=True)
                st.write("**Status**: DocumentProcessor initialized")
                st.write("**OpenAI API**: âœ… Configured")
                st.write("**Components**: File extractors, Neo4j integration")
            elif has_api_key:
                st.markdown('<div class="status-box status-warning">âš¡ Pipeline Available - Needs Initialization</div>', unsafe_allow_html=True) 
                st.write("**OpenAI API**: âœ… Configured")
                st.write("**Status**: Ready to initialize")
            else:
                st.markdown('<div class="status-box status-error">âŒ Missing OpenAI API Key</div>', unsafe_allow_html=True)
                st.write("**Status**: Configure API key to enable pipeline")
                
        except Exception as e:
            st.markdown('<div class="status-box status-error">âŒ Pipeline Error</div>', unsafe_allow_html=True)
            st.write(str(e))

def show_architecture_page():
    """Show architecture overview"""
    st.header("ğŸ—ï¸ Direct Pipeline Architecture")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âœ… Completed Components")
        st.markdown("""
        **ğŸ—ï¸ Core Pipeline** (`src/core/pipeline/`)
        - [x] `document_processor.py` - Main orchestrator with 6-step pipeline
        - [x] File type detection and routing
        - [x] Integration with specialized extractors
        
        **ğŸ¯ Node Extractors** (`src/core/node_extractor/`)
        - [x] `base_node_extractor.py` - Abstract base class
        - [x] `docx_node_extractor.py` - DOCX-specific extraction
        - [x] `pdf_node_extractor.py` - PDF-specific extraction  
        - [x] `excel_node_extractor.py` - Excel-specific extraction
        - [x] Factory function for extractor selection
        
        **ğŸ“ Specialized Prompts** (`src/core/node_extractor/prompts/`)
        - [x] `docx_prompts.py` - DOCX extraction prompts
        - [x] `pdf_prompts.py` - PDF extraction prompts
        - [x] `excel_prompts.py` - Excel extraction prompts
        
        **ğŸ—„ï¸ Knowledge Graph** (`src/core/knowledge_graph/`)
        - [x] `kg_operations.py` - Direct Neo4j operations
        - [x] `neo4j_manager.py` - Database management
        """)
    
    with col2:
        st.subheader("ğŸ”„ Implementation TODOs")
        st.markdown("""
        **ğŸ”— Missing Components** (Need Implementation)
        - [ ] LLM client integration in base extractors
        - [ ] Image description components for each file type
        - [ ] Markdown conversion components  
        - [ ] Markdown chunking components
        - [ ] Complete end-to-end testing
        
        **ğŸš€ Next Steps:**
        - [ ] Implement LLM client in `BaseNodeExtractor` 
        - [ ] Complete image describer components
        - [ ] Complete markdown converter components
        - [ ] Complete markdown chunker components
        - [ ] Test full pipeline with real documents
        
        **ğŸ›ï¸ Architecture Benefits:**
        - Clear separation of responsibilities
        - File-type specific optimization
        - No wrapper abstraction complexity
        - Easy to test and maintain
        - Scalable for new file types
        
        **ğŸ—‚ï¸ Legacy Files Moved to `legacy_files/`:**
        - `graphiti_wrapper.py` - Replaced by direct pipeline
        - `entity_extractor.py` - Replaced by node extractors
        """)


def show_document_processing_page():
    """Show document processing page with file upload and processing"""
    st.header("ğŸ“ Document Processing Pipeline")
    
    st.info("""
    **ğŸš€ Direct Pipeline Features:**
    - **File Type Detection**: Tá»± Ä‘á»™ng nháº­n diá»‡n DOCX, PDF, Excel
    - **Image Description**: MÃ´ táº£ hÃ¬nh áº£nh trong document báº±ng AI
    - **Markdown Conversion**: Chuyá»ƒn Ä‘á»•i sang markdown format
    - **Smart Chunking**: Chia nhá» document thÃ nh chunks cÃ³ Ã½ nghÄ©a
    - **Node Extraction**: TrÃ­ch xuáº¥t entities vÃ  relationships báº±ng LLM
    - **Neo4j Integration**: LÆ°u trá»¯ vÃ o knowledge graph database
    """)
    
    # File upload section
    st.subheader("ğŸ“¤ Upload Document")
    
    uploaded_file = st.file_uploader(
        "Chá»n file Ä‘á»ƒ xá»­ lÃ½:",
        type=['doc', 'docx', 'pdf', 'xlsx', 'xls'],
        help="Há»— trá»£: DOC (sáº½ tá»± Ä‘á»™ng chuyá»ƒn sang DOCX báº±ng LibreOffice), DOCX, PDF, Excel files. File sáº½ Ä‘Æ°á»£c xá»­ lÃ½ qua 6-step pipeline."
    )
    
    if uploaded_file is not None:
        # Display file info
        file_details = {
            "TÃªn file": uploaded_file.name,
            "Loáº¡i file": uploaded_file.type,
            "KÃ­ch thÆ°á»›c": f"{uploaded_file.size / 1024:.1f} KB"
        }
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**ğŸ“‹ ThÃ´ng tin file:**")
            for key, value in file_details.items():
                st.write(f"â€¢ {key}: {value}")
        
        with col2:
            st.write("**ğŸ”§ Tráº¡ng thÃ¡i Pipeline:**")
            if 'document_processor' in st.session_state:
                st.success("âœ… Pipeline sáºµn sÃ ng")
                st.write("â€¢ DocumentProcessor: âœ…")
                st.write("â€¢ LLM Client: âœ…")
                st.write("â€¢ Neo4j: âœ…")
            else:
                st.error("âŒ Pipeline chÆ°a khá»Ÿi táº¡o")
                st.write("â€¢ DocumentProcessor: âŒ")
                st.write("â€¢ LLM Client: âŒ")
                st.write("â€¢ Neo4j: âŒ")
        
        # Process button
        if st.button("ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ Document", type="primary", disabled='document_processor' not in st.session_state):
            if 'document_processor' in st.session_state:
                process_uploaded_file(uploaded_file)
            else:
                st.error("âŒ DocumentProcessor chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o! Vui lÃ²ng kiá»ƒm tra OpenAI API key.")
    
    # Processing history
    if 'processing_history' in st.session_state and st.session_state['processing_history']:
        st.subheader("ğŸ“š Lá»‹ch sá»­ xá»­ lÃ½")
        
        for i, history_item in enumerate(st.session_state['processing_history']):
            with st.expander(f"ğŸ“„ {history_item.get('filename', 'Unknown')} - {history_item.get('timestamp', 'Unknown')}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**Tráº¡ng thÃ¡i**: {history_item.get('status', 'Unknown')}")
                    st.write(f"**Loáº¡i file**: {history_item.get('file_type', 'Unknown')}")
                    st.write(f"**Chunks**: {history_item.get('chunks_processed', 0)}")
                with col2:
                    st.write(f"**Entities**: {history_item.get('entities_extracted', 0)}")
                    st.write(f"**Relationships**: {history_item.get('relationships_extracted', 0)}")
                    if history_item.get('neo4j_success'):
                        st.success("âœ… Neo4j Import thÃ nh cÃ´ng")
                    else:
                        st.error("âŒ Neo4j Import tháº¥t báº¡i")
    
    # Pipeline status
    st.subheader("ğŸ” Pipeline Status")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Pipeline Components", "6/6", "âœ… Complete")
        st.write("â€¢ File Detection")
        st.write("â€¢ Image Description")
        st.write("â€¢ Markdown Conversion")
    
    with col2:
        st.metric("File Types", "3/3", "âœ… Supported")
        st.write("â€¢ DOCX")
        st.write("â€¢ PDF")
        st.write("â€¢ Excel")
    
    with col3:
        st.metric("Neo4j Integration", "2/3", "ğŸ”„ Partial")
        st.write("â€¢ DOCX: âœ…")
        st.write("â€¢ Excel: âœ…")
        st.write("â€¢ PDF: ğŸ”„")

def process_uploaded_file(uploaded_file):
    """Process uploaded file using the document processor pipeline"""
    try:
        # Create temporary file
        import tempfile
        import os
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        st.info(f"ğŸ“ File táº¡m thá»i Ä‘Æ°á»£c lÆ°u táº¡i: {tmp_file_path}")
        
        # Process with pipeline
        with st.spinner("ğŸ”„ Äang xá»­ lÃ½ document..."):
            processor = st.session_state['document_processor']
            result = processor.process_document(tmp_file_path)
        
        # Save to processing history
        history_item = {
            'filename': uploaded_file.name,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'status': result.get('status', 'unknown'),
            'file_type': result.get('file_type', 'unknown'),
            'chunks_processed': result.get('chunks_processed', 0),
            'entities_extracted': result.get('entities_extracted', 0),
            'relationships_extracted': result.get('relationships_extracted', 0),
            'neo4j_success': result.get('neo4j_result', {}).get('success', False)
        }
        
        if 'processing_history' not in st.session_state:
            st.session_state['processing_history'] = []
        st.session_state['processing_history'].insert(0, history_item)
        
        # Display results
        st.subheader("ğŸ“‹ Káº¿t quáº£ xá»­ lÃ½")
        
        if result.get('status') == 'success':
            st.success("âœ… Xá»­ lÃ½ thÃ nh cÃ´ng!")
            
            # Results summary
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Chunks xá»­ lÃ½", result.get('chunks_processed', 0))
            with col2:
                st.metric("Entities", result.get('entities_extracted', 0))
            with col3:
                st.metric("Relationships", result.get('relationships_extracted', 0))
            
            # Pipeline steps summary
            st.subheader("ğŸ” Chi tiáº¿t Pipeline Steps")
            steps = [
                ("1ï¸âƒ£ File Detection", "âœ…", f"Detected: {result.get('file_type', 'Unknown')}"),
                ("2ï¸âƒ£ Image Description", "âœ…", "Completed"),
                ("3ï¸âƒ£ Markdown Conversion", "âœ…", "Completed"),
                ("4ï¸âƒ£ Chunking", "âœ…", f"{result.get('chunks_processed', 0)} chunks created"),
                ("5ï¸âƒ£ Node Extraction", "âœ…", f"{result.get('entities_extracted', 0)} entities, {result.get('relationships_extracted', 0)} relationships"),
                ("6ï¸âƒ£ Neo4j Storage", "âœ…" if result.get('neo4j_result', {}).get('success') else "âŒ", 
                 "Success" if result.get('neo4j_result', {}).get('success') else "Failed")
            ]
            
            for step, status, details in steps:
                st.write(f"{step} {status} {details}")
            
            # Detailed results
            with st.expander("ğŸ“Š Chi tiáº¿t káº¿t quáº£ JSON"):
                st.json(result)
            
            # Neo4j results
            neo4j_result = result.get('neo4j_result', {})
            if neo4j_result:
                st.subheader("ğŸ—„ï¸ Neo4j Import Results")
                if neo4j_result.get('success'):
                    st.success(f"âœ… Import thÃ nh cÃ´ng vÃ o Neo4j")
                    st.write(f"**Document**: {neo4j_result.get('document_name', 'N/A')}")
                    st.write(f"**Builder**: {neo4j_result.get('builder_used', 'N/A')}")
                    st.write(f"**Method**: {neo4j_result.get('import_method', 'N/A')}")
                else:
                    st.error(f"âŒ Import tháº¥t báº¡i: {neo4j_result.get('error', 'Unknown error')}")
            
            # Graph file info
            if result.get('graph_file_path'):
                st.info(f"ğŸ“„ Graph results Ä‘Æ°á»£c lÆ°u táº¡i: {result.get('graph_file_path')}")
        
        else:
            st.error(f"âŒ Xá»­ lÃ½ tháº¥t báº¡i: {result.get('error', 'Unknown error')}")
            with st.expander("ğŸ” Chi tiáº¿t lá»—i"):
                st.json(result)
        
        # Cleanup temporary file
        try:
            os.unlink(tmp_file_path)
            st.info("ğŸ§¹ File táº¡m thá»i Ä‘Ã£ Ä‘Æ°á»£c xÃ³a")
        except:
            pass
            
    except Exception as e:
        st.error(f"âŒ Lá»—i xá»­ lÃ½ file: {e}")
        st.error(f"Chi tiáº¿t lá»—i: {traceback.format_exc()}")
        
        # Save error to history
        if 'processing_history' not in st.session_state:
            st.session_state['processing_history'] = []
        
        error_history = {
            'filename': uploaded_file.name,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'status': 'error',
            'error': str(e)
        }
        st.session_state['processing_history'].insert(0, error_history)


def show_demo_page():
    """Show demo page for testing"""
    st.header("ğŸ§ª Direct Pipeline Demo")
    
    st.info("""
    **ğŸ—ï¸ Architecture Overview:**
    1. **File Type Detection** â†’ **Image Description**
    2. **Markdown Conversion** â†’ **Chunking** 
    3. **Specialized Node Extraction** (DOCX/PDF/Excel)
    4. **Neo4j Knowledge Graph Storage**
    
    **ğŸ’¡ Note**: Äá»ƒ xá»­ lÃ½ document thá»±c táº¿, hÃ£y sá»­ dá»¥ng trang **"ğŸ“ Document Processing"**
    """)
    
    # Sample text input for testing
    st.subheader("ğŸ§ª Test vá»›i Sample Text")
    sample_text = st.text_area(
        "Test vá»›i sample text (Direct Pipeline Demo):",
        value="We are developing a mobile banking application using React Native and Node.js. The app will have authentication, payment features, and a dashboard for users.",
        height=150
    )

    if st.button("ğŸš€ Test Direct Pipeline", type="primary"):
        if sample_text.strip():
            with st.spinner("Testing Direct Pipeline..."):
                try:
                    # Test with direct pipeline if available
                    if 'document_processor' in st.session_state:
                        processor = st.session_state['document_processor']
                        
                        st.info("â„¹ï¸ Real pipeline processes DOCX/PDF/Excel files. This is a simplified test.")
                        
                        # Simulate processing result
                        result = {
                            "status": "demo_mode",
                            "message": "Direct Pipeline Ready - Full implementation requires document files",
                            "pipeline_components": [
                                "âœ… DocumentProcessor initialized",
                                "âœ… File-specific node extractors (DOCX, PDF, Excel)",
                                "âœ… Specialized prompts for each file type", 
                                "âœ… Neo4j integration via kg_operations",
                                "âœ… Factory pattern for extractor selection"
                            ],
                            "next_steps": "Upload DOCX/PDF/Excel files for full processing"
                        }
                        
                    else:
                        result = {
                            "status": "not_initialized",
                            "message": "DocumentProcessor not initialized - check OpenAI API key"
                        }
                    
                    st.subheader("ğŸ“‹ Direct Pipeline Status")
                    st.json(result)
                        
                except Exception as e:
                    st.error(f"âŒ Error testing pipeline: {e}")
        else:
            st.warning("âš ï¸ Please enter some text!")

def get_available_documents():
    """Get list of available documents from Neo4j database"""
    try:
        # Query to get all document names
        query = """
        MATCH (d:Document) 
        WHERE d.file_name IS NOT NULL 
        RETURN DISTINCT d.file_name AS document_name 
        ORDER BY d.file_name;
        """
        
        results = neo4j_manager.execute_query(query=query)
        
        document_names = []
        for record in results:
            doc_name = record.get("document_name")
            if doc_name and doc_name.strip():
                document_names.append(doc_name.strip())
        
        return document_names
        
    except Exception as e:
        st.error(f"âŒ Lá»—i láº¥y danh sÃ¡ch documents: {e}")
        return []

def get_document_id_from_name(document_name: str) -> Optional[str]:
    """Get document ID from document name"""
    try:
        # Query to get document ID by file_name
        query = """
        MATCH (d:Document {file_name: $document_name})
        RETURN d.id as document_id
        LIMIT 1
        """
        
        results = neo4j_manager.execute_query(query=query, parameters={"document_name": document_name})
        
        if results and len(results) > 0:
            document_id = results[0].get("document_id")
            if document_id:
                return document_id
        
        return None
        
    except Exception as e:
        st.error(f"âŒ Lá»—i láº¥y Document ID: {e}")
        return None

def get_document_name_from_id(document_id: str) -> Optional[str]:
    """Get document name from document ID"""
    try:
        # Query to get document name by ID
        query = """
        MATCH (d:Document {id: $document_id})
        RETURN d.file_name as document_name
        LIMIT 1
        """
        
        results = neo4j_manager.execute_query(query=query, parameters={"document_id": document_id})
        
        if results and len(results) > 0:
            document_name = results[0].get("document_name")
            if document_name:
                return document_name
        
        return None
        
    except Exception as e:
        st.error(f"âŒ Lá»—i láº¥y Document Name: {e}")
        return None

def show_profile_generation_page():
    """Show profile generation page"""
    st.header("ğŸ‘¤ Profile Generation")
    
    st.info("""
    **ğŸ¯ Profile Generation Features:**
    - **Document Analysis**: PhÃ¢n tÃ­ch ná»™i dung document Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin project
    - **Category Classification**: Tá»± Ä‘á»™ng phÃ¢n loáº¡i project theo cÃ¡c categories
    - **Project Description**: Táº¡o mÃ´ táº£ project comprehensive
    - **Knowledge Graph Integration**: Sá»­ dá»¥ng Neo4j knowledge graph Ä‘á»ƒ retrieve context
    """)
    
    # Check if profile generator is available
    if 'profile_generator' not in st.session_state:
        st.error("âŒ ProfileGenerator chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o! Vui lÃ²ng kiá»ƒm tra OpenAI API key.")
        return
    
    # Document selection
    st.subheader("ğŸ“‹ Document Selection")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Get available documents from Neo4j
        available_documents = get_available_documents()
        
        # Create options list with "All Documents" as first option
        document_options = ["[Táº¥t cáº£ documents]"] + available_documents
        
        selected_document = st.selectbox(
            "Document Name:",
            options=document_options,
            index=0,
            help="Chá»n document Ä‘á»ƒ phÃ¢n tÃ­ch profile"
        )
        
        # Convert selection to document_name
        document_name = None if selected_document == "[Táº¥t cáº£ documents]" else selected_document
        
        # Show document scope info
        if document_name:
            st.info(f"ğŸ“„ **Document selected**: {document_name}")
        else:
            st.warning("âš ï¸ Vui lÃ²ng chá»n má»™t document cá»¥ thá»ƒ Ä‘á»ƒ generate profile!")
    
    with col2:
        st.write("**ğŸ“Š Available Categories:**")
        st.write("â€¢ BusinessCategory: B2B, B2C, B2E, B2G, C2C")
        st.write("â€¢ BusinessSize: Small/Medium, Enterprise")
        st.write("â€¢ ServiceCategory: Finance, Education, Healthcare, etc.")
        st.write("â€¢ IndustryCategory: IT, Construction, Manufacturing, etc.")
        st.write("â€¢ ServiceType: Consulting, Development, MVP, etc.")
        
        # Show available documents count
        if available_documents:
            st.success(f"âœ… {len(available_documents)} documents found")
            
            # Show first few document names
            with st.expander("ğŸ“‹ Document List"):
                for i, doc_name in enumerate(available_documents[:5], 1):
                    st.write(f"{i}. {doc_name}")
                if len(available_documents) > 5:
                    st.write(f"... vÃ  {len(available_documents) - 5} documents khÃ¡c")
        else:
            st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y documents trong Neo4j")
    
    # Generate profile button
    if st.button("ğŸš€ Generate Profile", type="primary", disabled=not document_name):
        if document_name:
            # Get document ID from document name
            document_id = get_document_id_from_name(document_name)
            if document_id:
                generate_profile(document_id, top_k=5)  # Use default top_k=5
            else:
                st.error(f"âŒ KhÃ´ng thá»ƒ tÃ¬m tháº¥y Document ID cho: {document_id}")
        else:
            st.warning("âš ï¸ Vui lÃ²ng chá»n má»™t document!")
    
    # Profile generation history
    if 'profile_history' in st.session_state and st.session_state['profile_history']:
        st.subheader("ğŸ“š Profile Generation History")
        
        for i, history_item in enumerate(st.session_state['profile_history']):
            # Get document name for display
            document_id = history_item.get('document_id', 'Unknown')
            document_name = get_document_name_from_id(document_id) if document_id != 'Unknown' else 'Unknown'
            display_name = document_name if document_name else f"ID: {document_id}"
            
            with st.expander(f"ğŸ“„ {display_name} - {history_item.get('timestamp', 'Unknown')}"):
                
                if history_item.get('status') == 'success':
                    # Show categories
                    st.write("**ğŸ·ï¸ Generated Categories:**")
                    categories = history_item.get('categories', {})
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        for category, info in list(categories.items())[:3]:
                            st.write(f"**{category}**: {info.get('label', 'Unknown')}")
                    
                    with col2:
                        for category, info in list(categories.items())[3:]:
                            st.write(f"**{category}**: {info.get('label', 'Unknown')}")
                    
                    # Show project description
                    st.write("**ğŸ“ Project Description:**")
                    description = history_item.get('project_description', 'N/A')
                    st.write(description)
                    
                    # Show detailed results
                    with st.expander("ğŸ“Š Chi tiáº¿t Categories"):
                        st.json(categories)
                
                else:
                    st.error(f"âŒ Generation failed: {history_item.get('error', 'Unknown error')}")

def generate_profile(document_id: str, top_k: int):
    """Generate profile for given document ID"""
    try:
        
        with st.spinner("ğŸ”„ Äang generate profile..."):
            profile_generator = st.session_state['profile_generator']
            result = profile_generator.run(document_id, top_k=top_k)
        
        # Save to profile history
        history_item = {
            'document_id': document_id,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'status': 'success',
            'top_k': top_k,
            'categories': result.get('categories', {}),
            'project_description': result.get('project_description', ''),
        }
        
        if 'profile_history' not in st.session_state:
            st.session_state['profile_history'] = []
        st.session_state['profile_history'].insert(0, history_item)
        
        # Display results
        st.subheader("ğŸ“‹ Profile Generation Results")
        
        st.success("âœ… Profile generation thÃ nh cÃ´ng!")
        
        # Show categories in a nice format
        st.subheader("ğŸ·ï¸ Project Categories")
        categories = result.get('categories', {})
        
        if categories:
            col1, col2 = st.columns(2)
            
            category_items = list(categories.items())
            mid_point = len(category_items) // 2
            
            with col1:
                for category, info in category_items[:mid_point]:
                    with st.container():
                        st.write(f"**{category}**")
                        st.info(f"ğŸ¯ {info.get('label', 'Unknown')}")
            
            with col2:
                for category, info in category_items[mid_point:]:
                    with st.container():
                        st.write(f"**{category}**")
                        st.info(f"ğŸ¯ {info.get('label', 'Unknown')}")
        
        # Show project description
        st.subheader("ğŸ“ Project Description")
        description = result.get('project_description', '')
        if description:
            st.write(description)
        else:
            st.warning("âš ï¸ KhÃ´ng thá»ƒ táº¡o project description")
        
        # Detailed results
        with st.expander("ğŸ“Š Detailed Categories Results"):
            st.json(categories)
        
        # Summary metrics
        st.subheader("ğŸ“ˆ Generation Summary")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Categories Generated", len(categories))
        with col2:
            st.metric("Top K Used", top_k)
        with col3:
            successful_categories = sum(1 for info in categories.values() if info.get('label') != 'Unknown')
            st.metric("Successful Classifications", successful_categories)
            
    except Exception as e:
        st.error(f"âŒ Lá»—i generate profile: {e}")
        st.error(f"Chi tiáº¿t lá»—i: {traceback.format_exc()}")
        
        # Save error to history
        if 'profile_history' not in st.session_state:
            st.session_state['profile_history'] = []
        
        error_history = {
            'document_id': document_id,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'status': 'error',
            'error': str(e)
        }
        st.session_state['profile_history'].insert(0, error_history)

def show_question_evaluation_page():
    """Show question evaluation page"""
    st.header("â“ Question Evaluation")
    
    st.info("""
    **ğŸ¤– Question Evaluation Features:**
    - **Question Answering**: Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn knowledge graph
    - **Hybrid Search**: Sá»­ dá»¥ng hybrid search Ä‘á»ƒ tÃ¬m relevant context
    - **Batch Processing**: Xá»­ lÃ½ nhiá»u cÃ¢u há»i tá»« JSON file
    - **Multi-language Support**: Há»— trá»£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh
    """)
    
    # Check if question evaluator is available
    if 'question_evaluator' not in st.session_state:
        st.error("âŒ QuestionEvaluator chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o! Vui lÃ²ng kiá»ƒm tra OpenAI API key.")
        return
    
    # Show question section directly
    show_question_section()

def show_question_section():
    """Show simplified question answering section"""
    st.subheader("â“ Question Answering")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Get available documents from Neo4j
        available_documents = get_available_documents()
        
        # Create options list with "All Documents" as first option
        document_options = ["[Táº¥t cáº£ documents]"] + available_documents
        
        selected_document = st.selectbox(
            "Document Name:",
            options=document_options,
            index=0,
            help="Chá»n document cá»¥ thá»ƒ hoáº·c search toÃ n bá»™ knowledge graph."
        )
        
        # Convert selection to document_name
        document_name = None if selected_document == "[Táº¥t cáº£ documents]" else selected_document
        
        # Show document scope info
        if document_name:
            st.info(f"ğŸ“„ **Document scope**: {document_name}")
        else:
            st.info("ğŸŒ **Document scope**: ToÃ n bá»™ knowledge graph")
    
    with col2:
        st.write("**ğŸ“„ Available Documents:**")
        
        # Show available documents count
        if available_documents:
            st.success(f"âœ… {len(available_documents)} documents found")
            
            # Show first few document names
            with st.expander("ğŸ“‹ Document List"):
                for i, doc_name in enumerate(available_documents[:5], 1):
                    st.write(f"{i}. {doc_name}")
                if len(available_documents) > 5:
                    st.write(f"... vÃ  {len(available_documents) - 5} documents khÃ¡c")
        else:
            st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y documents trong Neo4j")
    
    # Output filename
    st.subheader("âš™ï¸ Settings")
    output_filename = st.text_input(
        "Output Filename:",
        value="question_answers.json",
        help="TÃªn file Ä‘á»ƒ lÆ°u káº¿t quáº£"
    )
    
    # Process all questions button
    if st.button("ğŸš€ Process All Questions", type="primary"):
        process_all_questions_simplified(document_name, output_filename)
    
    # Display previous results if available
    if 'last_qa_results' in st.session_state:
        st.markdown("---")
        display_qa_results(st.session_state['last_qa_results'])

def process_all_questions_simplified(document_name: Optional[str], output_filename: str):
    """Process all questions using ask_all_questions method"""
    try:
        with st.spinner("ğŸ”„ Äang xá»­ lÃ½ táº¥t cáº£ questions..."):
            question_evaluator = st.session_state['question_evaluator']
            
            # Update document scope if provided
            if document_name:
                question_evaluator.document_name = document_name
                question_evaluator.retriever.document_name = document_name
            else:
                # Reset to global scope
                question_evaluator.document_name = None
                question_evaluator.retriever.document_name = None
            
            # Process all questions using default model (gpt-4.1)
            results = question_evaluator.ask_all_questions(
                output_path=output_filename,
                model_name="gpt-4.1"
            )
        
        if results:
            st.success(f"âœ… ÄÃ£ xá»­ lÃ½ {len(results)} cÃ¢u há»i thÃ nh cÃ´ng!")
            
            # Save results to session state to persist across reruns
            
            # Get Vietnam timezone
            vn_tz = pytz.timezone('Asia/Ho_Chi_Minh')
            vn_time = datetime.now(vn_tz)
            
            st.session_state['last_qa_results'] = {
                'results': results,
                'document_scope': document_name or 'global_graph',
                'output_file': output_filename,
                'timestamp': vn_time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # Save to QA history  
            answerable_count = sum(1 for r in results if r.get('answerable', False))
            history_item = {
                'type': 'batch_processing',
                'total_questions': len(results),
                'answerable_count': answerable_count,
                'timestamp': vn_time.strftime("%Y-%m-%d %H:%M:%S"),
                'document_scope': document_name or 'global_graph',
                'output_file': output_filename
            }
            
            if 'qa_history' not in st.session_state:
                st.session_state['qa_history'] = []
            st.session_state['qa_history'].insert(0, history_item)
            
            # Force display results immediately
            display_qa_results(st.session_state['last_qa_results'])
            
        else:
            st.error("âŒ KhÃ´ng cÃ³ cÃ¢u há»i nÃ o Ä‘Æ°á»£c xá»­ lÃ½!")
            
    except Exception as e:
        st.error(f"âŒ Lá»—i xá»­ lÃ½ questions: {e}")
        st.error(f"Chi tiáº¿t lá»—i: {traceback.format_exc()}")

def display_qa_results(qa_results_data):
    """Display Q&A results with filtering options - persists across reruns"""
    results = qa_results_data['results']
    document_scope = qa_results_data['document_scope']
    output_file = qa_results_data['output_file']
    timestamp = qa_results_data['timestamp']
    
    # Show summary
    st.subheader("ğŸ“Š Processing Summary")
    
    answerable_count = sum(1 for r in results if r.get('answerable', False))
    successful_count = sum(1 for r in results if not r.get('error'))
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Questions", len(results))
    with col2:
        st.metric("Answerable", answerable_count)
    with col3:
        st.metric("Successful", successful_count)
    
    # Show processing info
    st.info(f"ğŸ“„ **Document scope**: {document_scope} | â° **Processed**: {timestamp}")
    
    # View options
    col1, col2 = st.columns([3, 1])
    with col1:
        st.subheader("ğŸ“‹ All Questions & Answers")
    with col2:
        show_details = st.checkbox("Show Details", value=True, help="Show related context and metadata", key="show_details_cb")
    
    # Filter options  
    filter_col1, filter_col2 = st.columns(2)
    with filter_col1:
        show_answerable = st.checkbox("Show Answerable Only", value=False, help="Filter to show only answerable questions", key="show_answerable_cb")
    with filter_col2:
        show_unanswerable = st.checkbox("Show Unanswerable Only", value=False, help="Filter to show only unanswerable questions", key="show_unanswerable_cb")
    
    # Apply filters
    filtered_results = results
    if show_answerable and not show_unanswerable:
        filtered_results = [r for r in results if r.get('answerable', False)]
    elif show_unanswerable and not show_answerable:
        filtered_results = [r for r in results if not r.get('answerable', False)]
    
    st.write(f"**Showing {len(filtered_results)} of {len(results)} questions**")
    
    # Display filtered results
    for i, result in enumerate(filtered_results):
        # Find original index for numbering
        original_index = results.index(result) + 1
        
        answerable_icon = "âœ…" if result.get('answerable') else "âŒ"
        question_preview = result.get('question', 'Unknown')[:80]
        
        with st.expander(f"{answerable_icon} Question {original_index}: {question_preview}..."):
            
            # Question
            st.write("**â“ Question:**")
            st.write(result.get('question', 'N/A'))
            
            # Answer status
            st.write(f"**ğŸ¯ Answerable**: {'âœ… Yes' if result.get('answerable') else 'âŒ No'}")
            
            # Answer - show full content
            st.write("**ğŸ’¬ Answer:**")
            answer_text = result.get('answer', 'N/A')
            if answer_text and answer_text.strip():
                # Display full answer without truncation
                st.markdown(answer_text)
            else:
                st.write("*No answer provided*")
            
            # Show details if enabled
            if show_details:
                # Related context if available
                if result.get('related_context'):
                    st.write("**ğŸ“š Related Context:**")
                    st.markdown(result.get('related_context', ''))
    
    st.info(f"ğŸ“ Full results saved to: {output_file}")

def main():
    """Main app function"""
    # Header
    st.markdown('<h1 class="main-header">ğŸ•¸ï¸ Knowledge Graph Document Analyzer</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #666;">Direct Pipeline Architecture - Personal Project</p>', unsafe_allow_html=True)
    
    # Initialize system
    if 'initialized' not in st.session_state:
        st.session_state['initialized'] = initialize_system()
    
    # Sidebar navigation
    st.sidebar.title("ğŸ§­ Navigation")
    page = st.sidebar.selectbox(
        "Chá»n trang:",
        ["ğŸ“Š System Status", "ğŸ—ï¸ Architecture", "ğŸ“ Document Processing", "ğŸ§ª Demo", "ğŸ‘¤ Profile Generation", "â“ Question Evaluation"]
    )
    
    # System info in sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ”§ System Info")
    st.sidebar.write(f"**OpenAI API**: {'âœ…' if ai_config.api_key else 'âŒ'}")
    st.sidebar.write(f"**Neo4j**: {'âœ…' if neo4j_manager.is_connected() else 'âŒ'}")
    st.sidebar.write(f"**Pipeline**: {'âœ…' if 'document_processor' in st.session_state else 'âŒ'}")
    st.sidebar.write(f"**Profile Gen**: {'âœ…' if 'profile_generator' in st.session_state else 'âŒ'}")
    st.sidebar.write(f"**QA Evaluator**: {'âœ…' if 'question_evaluator' in st.session_state else 'âŒ'}")
    
    # Pipeline status in sidebar
    if 'document_processor' in st.session_state:
        st.sidebar.markdown("### ğŸš€ Pipeline Status")
        st.sidebar.success("âœ… DocumentProcessor Ready")
        st.sidebar.write("**File Types**: DOCX, PDF, Excel")
        st.sidebar.write("**Components**: 6/6 Ready")
        
        # Processing history summary
        if 'processing_history' in st.session_state and st.session_state['processing_history']:
            st.sidebar.markdown("### ğŸ“š Recent Processing")
            recent_count = min(3, len(st.session_state['processing_history']))
            for i in range(recent_count):
                item = st.session_state['processing_history'][i]
                status_icon = "âœ…" if item.get('status') == 'success' else "âŒ"
                st.sidebar.write(f"{status_icon} {item.get('filename', 'Unknown')}")
        
        # New components status
        st.sidebar.markdown("### ğŸ†• New Components")
        if 'profile_generator' in st.session_state:
            st.sidebar.success("âœ… ProfileGenerator Ready")
        if 'question_evaluator' in st.session_state:
            st.sidebar.success("âœ… QuestionEvaluator Ready")
        
        # QA History summary
        if 'qa_history' in st.session_state and st.session_state['qa_history']:
            st.sidebar.markdown("### â“ Recent Q&A")
            recent_qa_count = min(2, len(st.session_state['qa_history']))
            for i in range(recent_qa_count):
                qa_item = st.session_state['qa_history'][i]
                if qa_item.get('type') == 'batch_processing':
                    answerable_count = qa_item.get('answerable_count', 0)
                    total_questions = qa_item.get('total_questions', 0)
                    st.sidebar.write(f"ğŸ“Š Batch: {answerable_count}/{total_questions} answered")
                else:
                    answerable_icon = "âœ…" if qa_item.get('answerable') else "âŒ"
                    question_preview = qa_item.get('question', 'Unknown')[:30]
                    st.sidebar.write(f"{answerable_icon} {question_preview}...")
        
        # Profile History summary
        if 'profile_history' in st.session_state and st.session_state['profile_history']:
            st.sidebar.markdown("### ğŸ‘¤ Recent Profiles")
            recent_profile_count = min(2, len(st.session_state['profile_history']))
            for i in range(recent_profile_count):
                profile_item = st.session_state['profile_history'][i]
                profile_icon = "âœ…" if profile_item.get('status') == 'success' else "âŒ"
                doc_id = profile_item.get('document_id', 'Unknown')
                doc_name = get_document_name_from_id(doc_id) if doc_id != 'Unknown' else 'Unknown'
                display_name = doc_name if doc_name else f"ID: {doc_id[:15]}..."
                st.sidebar.write(f"{profile_icon} {display_name}")
    else:
        st.sidebar.markdown("### ğŸš€ Pipeline Status")
        st.sidebar.error("âŒ Pipeline Not Ready")
        st.sidebar.write("**Check**: OpenAI API Key")
        st.sidebar.write("**Status**: Needs Configuration")
    
    # Page routing
    if page == "ğŸ“Š System Status":
        show_system_status()
    elif page == "ğŸ—ï¸ Architecture":
        show_architecture_page()
    elif page == "ğŸ“ Document Processing":
        show_document_processing_page()
    elif page == "ğŸ§ª Demo":
        show_demo_page()
    elif page == "ğŸ‘¤ Profile Generation":
        show_profile_generation_page()
    elif page == "â“ Question Evaluation":
        show_question_evaluation_page()

if __name__ == "__main__":
    main()
